{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw2.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Способы решения данной задачи:\n",
        "* Решение в лоб - перебрать тексты regex выржанием по словарю синонимов. Иначе - поиск с помощью ключевых слов категорий\n",
        "* Использование статистического анализа для извлечения важности слова в тексте\n",
        "* Классификация с помощью структурных признаков\n",
        "* Получение списка схожих слов с помощью embeddings, получение коллокаций с помощью этого списка\n",
        "\n"
      ],
      "metadata": {
        "id": "VRd9FBuyIv2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь загрузим корпус отзывов про товары:"
      ],
      "metadata": {
        "id": "FoQ2bSUXU4h-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIhwzd4XEn6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ee5a21-8050-4d8a-970f-912500b0838c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 16:17:56--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45409631 (43M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Cell_Phones_and_Accessories_5.json.gz.2’\n",
            "\n",
            "reviews_Cell_Phones 100%[===================>]  43.31M  14.7MB/s    in 2.9s    \n",
            "\n",
            "2021-12-18 16:18:00 (14.7 MB/s) - ‘reviews_Cell_Phones_and_Accessories_5.json.gz.2’ saved [45409631/45409631]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('reviews_Cell_Phones_and_Accessories_5.json.gz')"
      ],
      "metadata": {
        "id": "icgSWU-wKgQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('genesis')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = stopwords.words('english')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6cm4CTuQzXO",
        "outputId": "4180281f-fcf6-4fff-e5d1-27d465c74f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим предобученную модель word2vec, найдем похожие слова:"
      ],
      "metadata": {
        "id": "4mOnbdczUUrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBewcfLkSXqe",
        "outputId": "39bd951f-d44e-40af-8e8d-126bef6efd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 16:18:24--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.94\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True,limit=100000)"
      ],
      "metadata": {
        "id": "f9nh8v3gQiuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ищем похожие слова\n",
        "top=model.most_similar(positive=['iPhone'], topn = 10)\n",
        "result_search = []\n",
        "for i in top:\n",
        "  result_search.append(i[0])\n",
        "print(result_search)"
      ],
      "metadata": {
        "id": "oVbbGv1IUQXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зададим функции вывода n-грам:"
      ],
      "metadata": {
        "id": "2SVCK3vNUlZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nbest(self, score_fn, n):\n",
        "    return [p for p,s in self.score_ngrams(score_fn)[:n]]"
      ],
      "metadata": {
        "id": "BqidBYNQQneK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_ngrams(self, score_fn):\n",
        "    return sorted(self._score_ngrams(score_fn),\n",
        "                  key=itemgetter(1), reverse=True)"
      ],
      "metadata": {
        "id": "Tl4KkSqQQwuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдем n-граммы и отсортируем их по различным метрикам:"
      ],
      "metadata": {
        "id": "31lRXKkEUsjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "text = df['reviewText'][50]\n",
        "print(text)\n",
        "creature_filter = lambda *w: result_search not in w\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "\n",
        "text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
        "text = \" \".join([word for word in text.split() if word not in (stop)])\n",
        "\n",
        "finder_b = BigramCollocationFinder.from_words(word_tokenize(text))\n",
        "finder_t = TrigramCollocationFinder.from_words(word_tokenize(text))\n",
        "\n",
        "#finder_b.apply_ngram_filter(creature_filter)\n",
        "#finder_t.apply_ngram_filter(creature_filter)\n"
      ],
      "metadata": {
        "id": "MEz_5quqQ_Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Result for trigrams.')\n",
        "print('likelihood_ratio: ')\n",
        "for i in finder_t.score_ngrams(trigram_measures.likelihood_ratio):\n",
        "    print(i)\n",
        "print('pmi: ')\n",
        "for i in finder_t.score_ngrams(trigram_measures.pmi):\n",
        "    print(i)\n",
        "print('jaccard: ')\n",
        "for i in finder_t.score_ngrams(trigram_measures.jaccard):\n",
        "    print(i)\n",
        "\n",
        "print('Result for bigrams.')\n",
        "print('likelihood_ratio')\n",
        "for i in finder_b.score_ngrams(bigram_measures.likelihood_ratio):\n",
        "    print(i)\n",
        "print('pmi: ')\n",
        "for i in finder_b.score_ngrams(bigram_measures.pmi):\n",
        "    print(i)\n",
        "print('jaccard: ')\n",
        "for i in finder_b.score_ngrams(bigram_measures.jaccard):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "EJDFcHrWN17C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}